{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert this notebook to executable python script using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- jupyter nbconvert --to python Analyze_RRM.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as path\n",
    "import psutil\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pickle\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from datetime import date, datetime, timedelta, time\n",
    "from timeit import default_timer as timer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC, SVR\n",
    "#from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "#from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, average_precision_score\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_running_file_dir = sys.path[0]\n",
    "current_running_file_par = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, os.path.join(current_running_file_par, 'Step1_ExtractData'))\n",
    "sys.path.insert(0, os.path.join(current_running_file_par, 'Step2_PrepareData'))\n",
    "sys.path.insert(0, os.path.join(current_running_file_par, 'Step3_TrainModel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Extract_DFM_Data_Helper import *\n",
    "from Prepare_TrainTest_Data_Helper import *\n",
    "from TrainModel_Helper import *\n",
    "from Analyze_Helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Start Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start_time = timer()\n",
    "process = psutil.Process(os.getpid())\n",
    "global_initial_memory = process.memory_info().rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Input JSON File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file name when using jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_extract_data = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Extract/json_extract_data_039.json'\n",
    "json_file_prep_data    = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Prep/json_prep_data_label_006.json'\n",
    "json_file_train_model  = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Train/json_train_model_007.json'\n",
    "json_file_trends      = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Trends/json_trends_002.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file name when using python script on command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_file_extract_data = sys.argv[1]\n",
    "#json_file_prep_data = sys.argv[2]\n",
    "#json_file_train_model = sys.argv[3]\n",
    "#json_file_trends  = sys.argv[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for extracting data: \\n {}'.format(json_file_extract_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_extract_data) as json_file_handle:\n",
    "    json_content_extract_data = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_extract_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for preparing data: \\n {}'.format(json_file_prep_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_prep_data) as json_file_handle:\n",
    "    json_content_prep_data = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_prep_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for training model: \\n {}'.format(json_file_train_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_train_model) as json_file_handle:\n",
    "    json_content_train_model = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for analysis of trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for analysis: \\n {}'.format(json_file_trends))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_trends) as json_file_handle:\n",
    "    json_content_trends = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables to be Used for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current data set params\n",
    "data_set_count = json_content_extract_data['data_set_defn']['data_set_count']\n",
    "max_history_to_consider = json_content_extract_data['data_set_defn']['max_history_to_consider']\n",
    "history_interval = json_content_extract_data['data_set_defn']['history_interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labels = json_content_extract_data['features_labels']\n",
    "qois_to_read = features_labels['qois_to_read']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nevada Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevada_data = json_content_extract_data['nevada_data']\n",
    "remove_nevada = nevada_data['remove_nevada']\n",
    "j_nevada, i_nevada = nevada_data['j_nevada'], nevada_data['i_nevada']\n",
    "j_anchor, i_anchor = nevada_data['j_anchor'], nevada_data['i_anchor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Data for Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_data_train_test = json_content_extract_data['clip_data_train_test']\n",
    "x_clip_train_test = clip_data_train_test['x_clip']\n",
    "y_clip_train_test = clip_data_train_test['y_clip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Label, FM Threshold etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = json_content_prep_data['label_defn']['label_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_labels = json_content_prep_data['FM_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_label_type = FM_labels['label_type']\n",
    "\n",
    "class_labels = None\n",
    "if (FM_label_type == 'Binary'):\n",
    "    FM_binary_threshold = FM_labels['FM_binary_threshold']\n",
    "    class_labels = range(2)\n",
    "if (FM_label_type == 'MultiClass'):\n",
    "    FM_MC_levels = FM_labels['FM_MC_levels']\n",
    "    class_labels = range(len(FM_MC_levels) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_hr = json_content_prep_data['qoi_to_plot']['FM_hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qois_to_use = json_content_prep_data['features']['qois_to_use']\n",
    "qois_derived = json_content_prep_data['features']['qois_derived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_data = json_content_prep_data['prune_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ML Model and Params etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_count = json_content_train_model['models']['model_count']\n",
    "scaler_type = json_content_train_model['models']['scaler_type']\n",
    "model_name = json_content_train_model['models']['model_name'] # ['RF', SVM', 'MLP']\n",
    "#model_params = json_content_train_model['models']['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Trends Analysis Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_count = json_content_trends['trends_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_data_loc = json_content_trends[\"base_data_loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year_range = json_content_trends[\"year_range\"]\n",
    "year = json_content_trends[\"year\"]\n",
    "start_time_stamp = json_content_trends[\"start_time_stamp\"]\n",
    "start_time_for_avg = json_content_trends[\"start_time_for_avg\"]\n",
    "end_time_for_avg = json_content_trends[\"end_time_for_avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_file_name = json_content_trends[\"base_file_name\"]\n",
    "CA_mask_file_name = json_content_trends[\"CA_mask_file_name\"]\n",
    "CA_mask_file = os.path.join(base_data_loc, CA_mask_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_interval = json_content_trends[\"prediction_interval\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_data_paths = json_content_trends['paths']\n",
    "trends_data_base_loc = trends_data_paths['trends_data_base_loc']\n",
    "os.system('mkdir -p %s'%trends_data_base_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths and File Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files_location = json_content_extract_data['paths']['data_files_location']\n",
    "trained_model_base_loc = json_content_train_model['paths']['trained_model_base_loc']\n",
    "trends_data_base_loc = json_content_trends['paths']['trends_data_base_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_data_paths = json_content_analyze['paths']['raw_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet, Label, and Model Specific (Trained Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_name = 'dataset_%03d_label_%03d_%s_model_%03d_%s'%(data_set_count, \\\n",
    "                                                        label_count, FM_label_type, \\\n",
    "                                                        model_count, model_name)\n",
    "\n",
    "trained_model_loc = os.path.join(trained_model_base_loc, trained_model_name)\n",
    "\n",
    "trained_model_file_name = '{}_model.pkl'.format(trained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('mkdir -p %s'%filedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = generate_seed()\n",
    "random_state = init_random_generator(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_file = os.path.join(trained_model_loc, trained_model_file_name)\n",
    "model = pickle.load(open(trained_model_file, 'rb'))\n",
    "print ('\\nLoaded the ML model file at: {}\\n'.format(trained_model_file))\n",
    "print ('The model loaded is: {} \\n'.format(model))\n",
    "print ('Model params: \\n {}'.format(model.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the RRM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "U_var = 'WINDSPD_10M'\n",
    "T_var = 'TREFHT'\n",
    "SW_var = 'FSDS'\n",
    "RH_var = 'RHREFHT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_U = read_single_RRM_file (base_data_loc, year_range, base_file_name, U_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_T = read_single_RRM_file (base_data_loc, year_range, base_file_name, T_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_SW = read_single_RRM_file (base_data_loc, year_range, base_file_name, SW_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_RH = read_single_RRM_file (base_data_loc, year_range, base_file_name, RH_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play around with data read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_U\n",
    "#np.array(data_U['WINDSPD_10M'][0]).shape\n",
    "#data_T\n",
    "#np.array(data_T['TREFHT'][0]).shape\n",
    "#data_RH\n",
    "#np.array(data_RH['RHREFHT'][0]).shape\n",
    "#data_SW\n",
    "#np.array(data_SW['FSDS'][0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lat_lon_file = os.path.join(base_data_loc, 'CAne32x32v1pg2.latlon.nc')\n",
    "CA_mask_file = os.path.join(base_data_loc, 'CA_shp_mask_CAx32v1pg2.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lat_lon_data = xr.open_dataset(lat_lon_file)\n",
    "CA_mask_data = xr.open_dataset(CA_mask_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_mask_info = np.array(CA_mask_data['CA_shp_mask_CAx32v1pg2'])\n",
    "masked_ind = np.where(ca_mask_info == 1)[0]\n",
    "lat_info = np.array(CA_mask_data['lat'])\n",
    "lon_info = np.array(CA_mask_data['lon'])\n",
    "area_info = np.array(CA_mask_data['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframes at Time Stamps of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time_stamp_for_avg = '{}-{}'.format(year, start_time_for_avg)\n",
    "end_time_stamp_for_avg = '{}-{}'.format(year, end_time_for_avg)\n",
    "fuel_moisture_time_index_start = get_time_diff_hours(start_time_stamp, start_time_stamp_for_avg)\n",
    "fuel_moisture_time_index_end   = get_time_diff_hours(start_time_stamp,   end_time_stamp_for_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fuel_moisture_time_indices_for_averagring = np.arange(fuel_moisture_time_index_start, \\\n",
    "                                                      fuel_moisture_time_index_end + 1,\\\n",
    "                                                      prediction_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fuel_moisture_time_indices_for_averagring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_sum = np.zeros_like(labels_pred, np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pred_sum, pred_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pred_avg.min(), pred_avg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fuel_moisture_time_index in fuel_moisture_time_indices_for_averagring:\n",
    "    current_time_stamp = np.array(data_U['time'])[fuel_moisture_time_index].strftime('%Y-%m-%d_%H')\n",
    "    df_features = create_df_at_timestamp (fuel_moisture_time_index, max_history_to_consider, history_interval, \\\n",
    "                                      data_U, data_T, data_RH, data_SW)\n",
    "    df_features_masked = df_features.iloc[masked_ind]\n",
    "    \n",
    "    ### Scale Features\n",
    "    print ('Data scaler type: {}'.format(scaler_type))\n",
    "    scaler = define_scaler (scaler_type)\n",
    "    X_gt = df_features_masked\n",
    "    scaler.fit(X_gt)\n",
    "    X_gt_scaled = scaler.transform(X_gt)\n",
    "    \n",
    "    ### Prediction and Evaluation with Trained Model\n",
    "    labels_pred = predict(model, X_gt_scaled, \"Data at TimeStamp\")\n",
    "    pred_sum += labels_pred\n",
    "    \n",
    "    ### Plots\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    cont_levels = np.linspace(0, 0.3, 11)\n",
    "    cont = ax.scatter(lon_info[masked_ind], lat_info[masked_ind], c = labels_pred, marker = 's', s= 5, cmap = 'hot', vmin=0, vmax=0.3)\n",
    "    cbar = fig.colorbar(cont, ticks=cont_levels, extend = 'max')\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    plt.xlabel('Longitude (deg)')\n",
    "    plt.ylabel('Latitude (deg)')\n",
    "    plt.title(current_time_stamp)\n",
    "    '''\n",
    "\n",
    "pred_avg = pred_sum/len(fuel_moisture_time_indices_for_averagring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Plots\n",
    "fig, ax = plt.subplots()\n",
    "cont_levels = np.linspace(0, 0.3, 11)\n",
    "cont = ax.scatter(lon_info[masked_ind], lat_info[masked_ind], c = pred_avg -0.05, marker = 's', s= 3, cmap = 'hot', vmin=0, vmax=0.3)\n",
    "cbar = fig.colorbar(cont, ticks=cont_levels, extend = 'max')\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "plt.xlabel('Longitude (deg)')\n",
    "plt.ylabel('Latitude (deg)')\n",
    "plt.title('{} through {} every {} hrs'.format(start_time_stamp_for_avg, end_time_stamp_for_avg, prediction_interval))\n",
    "\n",
    "\n",
    "fig_file_name = 'FM_{}_{}_every_{}_hrs'.format(year_range, year, prediction_interval)\n",
    "plt.savefig(os.path.join(trends_data_base_loc, fig_file_name), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yearly_avg_file_name = 'FM_{}_{}_every_{}_hrs.pkl'.format(year_range, year, prediction_interval)\n",
    "pickle.dump({'pred_avg': pred_avg}, open(os.path.join(trends_data_base_loc,yearly_avg_file_name), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global End Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_final_memory = process.memory_info().rss\n",
    "global_end_time = timer()\n",
    "global_memory_consumed = global_final_memory - global_initial_memory\n",
    "print('Total memory consumed: {:.3f} MB'.format(global_memory_consumed/(1024*1024)))\n",
    "print('Total computing time: {:.3f} s'.format(global_end_time - global_start_time))\n",
    "print('=========================================================================')\n",
    "print(\"SUCCESS: Done Training and Testing of Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_ml_conda",
   "language": "python",
   "name": "py3_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
