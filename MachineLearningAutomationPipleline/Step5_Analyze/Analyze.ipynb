{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert this notebook to executable python script using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- jupyter nbconvert --to python Analyze.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as path\n",
    "import psutil\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pickle\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from datetime import date, datetime, timedelta, time\n",
    "from timeit import default_timer as timer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC, SVR\n",
    "#from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "#from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, average_precision_score\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_running_file_dir = sys.path[0]\n",
    "current_running_file_par = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, os.path.join(current_running_file_par, 'Step1_ExtractData'))\n",
    "sys.path.insert(0, os.path.join(current_running_file_par, 'Step2_PrepareData'))\n",
    "sys.path.insert(0, os.path.join(current_running_file_par, 'Step3_TrainModel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Extract_DFM_Data_Helper import *\n",
    "from Prepare_TrainTest_Data_Helper import *\n",
    "from TrainModel_Helper import *\n",
    "from Analyze_Helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# []\n",
    "'''\n",
    "To move this to helper function. Need to tackel the path\n",
    "'''\n",
    "def scale_predict_plot(FM_label_type, model, model_name, scaler_type, X_gt, y_gt, \\\n",
    "                       analysis_data_loc, analysis_scatter_file_name, \\\n",
    "                       max_data_size_scatter, fig_size_x, fig_size_y, \\\n",
    "                       font_size, x_lim, \\\n",
    "                       analysis_cm_file_name,\n",
    "                       normalize_cm, \\\n",
    "                        class_labels, \\\n",
    "                       j_indices, i_indices,\\\n",
    "                       analysis_fuel_map_file_name):\n",
    "    \n",
    "    ### Scale Features\n",
    "    print ('Data scaler type: {}'.format(scaler_type))\n",
    "    scaler = define_scaler (scaler_type)\n",
    "    scaler.fit(X_gt)\n",
    "    X_gt_scaled = scaler.transform(X_gt)\n",
    "\n",
    "    ### Prediction and Evaluation with Trained Model\n",
    "    labels_pred = predict(model, X_gt_scaled, \"Data at TimeStamp\")\n",
    "\n",
    "    accuracy = get_accuracy_score(model, FM_label_type, \\\n",
    "                                       X_gt_scaled, y_gt, labels_pred,\\\n",
    "                                       \"Data at TimeStamp\")\n",
    "\n",
    "    if (FM_label_type == 'Binary' or FM_label_type == 'MultiClass'):\n",
    "        conf_mat = get_confusion_matrix (FM_label_type, y_gt, labels_pred, \\\n",
    "                                          \"Data at TimeStamp\", class_labels)\n",
    "        get_classification_report (FM_label_type, y_gt, labels_pred, \\\n",
    "                              \"Data at TimeStamp\", class_labels)\n",
    "    else:\n",
    "        conf_mat = None\n",
    "        print('Confusion Matrix is not suitable for label_type: {}'.format(FM_label_type))\n",
    "\n",
    "\n",
    "    if (FM_label_type == 'Binary'):\n",
    "        average_precision_train = average_precision_score(y_gt, labels_pred)\n",
    "        print('Average precision-recall score for Train Data: {0:0.2f}'.format(\n",
    "              average_precision_train))\n",
    "\n",
    "\n",
    "    ### Plot Scatter or Confusion Matrix\n",
    "    if (FM_label_type == 'Regression'):\n",
    "        plot_scatter_regression (y_gt.to_numpy(), labels_pred, accuracy, model_name, \\\n",
    "                                analysis_data_loc, analysis_scatter_file_name, \\\n",
    "                                max_data_size_scatter, fig_size_x, fig_size_y, \\\n",
    "                                font_size, x_lim)\n",
    "    else:\n",
    "        plot_confusion_matrix (conf_mat, accuracy, model_name, \\\n",
    "                               analysis_data_loc, analysis_cm_file_name, \\\n",
    "                               fig_size_x, fig_size_y, \\\n",
    "                               font_size,\\\n",
    "                               normalize_cm, \\\n",
    "                               class_labels)\n",
    "\n",
    "\n",
    "    ### Plot Ground Truth and Prediction At the Desired Time Stamp\n",
    "    plot_fm (y_gt, labels_pred, j_indices, i_indices, FM_label_type, \\\n",
    "             analysis_data_loc, analysis_fuel_map_file_name, class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Start Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start_time = timer()\n",
    "process = psutil.Process(os.getpid())\n",
    "global_initial_memory = process.memory_info().rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Input JSON File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file name when using jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_extract_data = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Extract/json_extract_data_039.json'\n",
    "json_file_prep_data    = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Prep/json_prep_data_label_007.json'\n",
    "json_file_train_model  = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Train/json_train_model_009.json'\n",
    "json_file_analyze      = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Analyze/json_analyze_001.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file name when using python script on command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_file_extract_data = sys.argv[1]\n",
    "#json_file_prep_data = sys.argv[2]\n",
    "#json_file_train_model = sys.argv[3]\n",
    "#json_file_analyze  = sys.argv[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for extracting data: \\n {}'.format(json_file_extract_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_extract_data) as json_file_handle:\n",
    "    json_content_extract_data = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_extract_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for preparing data: \\n {}'.format(json_file_prep_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_prep_data) as json_file_handle:\n",
    "    json_content_prep_data = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_prep_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for training model: \\n {}'.format(json_file_train_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_train_model) as json_file_handle:\n",
    "    json_content_train_model = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for analysis: \\n {}'.format(json_file_analyze))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_analyze) as json_file_handle:\n",
    "    json_content_analyze = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables to be Used for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current data set params\n",
    "data_set_count = json_content_extract_data['data_set_defn']['data_set_count']\n",
    "max_history_to_consider = json_content_extract_data['data_set_defn']['max_history_to_consider']\n",
    "history_interval = json_content_extract_data['data_set_defn']['history_interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labels = json_content_extract_data['features_labels']\n",
    "qois_to_read = features_labels['qois_to_read']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nevada Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevada_data = json_content_extract_data['nevada_data']\n",
    "remove_nevada = nevada_data['remove_nevada']\n",
    "j_nevada, i_nevada = nevada_data['j_nevada'], nevada_data['i_nevada']\n",
    "j_anchor, i_anchor = nevada_data['j_anchor'], nevada_data['i_anchor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Data for Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_data_train_test = json_content_extract_data['clip_data_train_test']\n",
    "x_clip_train_test = clip_data_train_test['x_clip']\n",
    "y_clip_train_test = clip_data_train_test['y_clip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Label, FM Threshold etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = json_content_prep_data['label_defn']['label_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_labels = json_content_prep_data['FM_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_label_type = FM_labels['label_type']\n",
    "\n",
    "class_labels = None\n",
    "if (FM_label_type == 'Binary'):\n",
    "    FM_binary_threshold = FM_labels['FM_binary_threshold']\n",
    "    class_labels = range(2)\n",
    "if (FM_label_type == 'MultiClass'):\n",
    "    FM_MC_levels = FM_labels['FM_MC_levels']\n",
    "    class_labels = range(len(FM_MC_levels) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_hr = json_content_prep_data['qoi_to_plot']['FM_hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qois_to_use = json_content_prep_data['features']['qois_to_use']\n",
    "qois_derived = json_content_prep_data['features']['qois_derived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_data = json_content_prep_data['prune_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ML Model and Params etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_count = json_content_train_model['models']['model_count']\n",
    "scaler_type = json_content_train_model['models']['scaler_type']\n",
    "model_name = json_content_train_model['models']['model_name'] # ['RF', SVM', 'MLP']\n",
    "#model_params = json_content_train_model['models']['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Analysis Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_count = json_content_analyze['analysis_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data_paths = json_content_analyze['paths']\n",
    "analysis_data_desired = json_content_analyze['analysis_data_desired']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types, Time Stamps and Regions of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data_defined = [analysis_data_elem \\\n",
    "                         for analysis_data_elem in analysis_data_desired \\\n",
    "                         if analysis_data_elem in json_content_analyze]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Analysis desired to be performed on the following data sets:\\n {}'.format(\\\n",
    "                                                            analysis_data_desired))\n",
    "\n",
    "print ('Time and Region Info available for these data sets out of those desired:\\n {}'\\\n",
    "                                                    .format(analysis_data_defined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_region_info = get_time_region_info (analysis_data_defined, json_content_analyze)\n",
    "time_region_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Plots Prefernces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = json_content_train_model['evaluation']\n",
    "fig_size_x = analysis['fig_size_x']\n",
    "fig_size_y = analysis['fig_size_y']\n",
    "font_size  = analysis['font_size']\n",
    "\n",
    "if (FM_label_type == 'Regression'):\n",
    "    max_data_size_scatter = analysis['max_data_size_scatter']\n",
    "    x_lim      = analysis['x_lim']\n",
    "    normalize_cm = False\n",
    "else:\n",
    "    max_data_size_scatter = None\n",
    "    x_lim      = None\n",
    "    normalize_cm = analysis['normalize_cm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths and File Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files_location = json_content_extract_data['paths']['data_files_location']\n",
    "trained_model_base_loc = json_content_train_model['paths']['trained_model_base_loc']\n",
    "analysis_data_base_loc = json_content_analyze['paths']['analysis_data_base_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_paths = json_content_analyze['paths']['raw_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet, Label, and Model Specific (Trained Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_name = 'dataset_%03d_label_%03d_%s_model_%03d_%s'%(data_set_count, \\\n",
    "                                                        label_count, FM_label_type, \\\n",
    "                                                        model_count, model_name)\n",
    "\n",
    "trained_model_loc = os.path.join(trained_model_base_loc, trained_model_name)\n",
    "\n",
    "trained_model_file_name = '{}_model.pkl'.format(trained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet, Label, Model, and TimeStamp Specific (Analysis Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'dataset_%03d_label_%03d_%s_model_%03d_%s_analysis_%03d'%(\\\n",
    "                                                        data_set_count, \\\n",
    "                                                        label_count, FM_label_type, \\\n",
    "                                                        model_count, model_name,\\\n",
    "                                                        analysis_count)\n",
    "\n",
    "analysis_loc = os.path.join(analysis_data_base_loc, analysis_name)\n",
    "os.system('mkdir -p %s'%analysis_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data_locations_all_types = get_analysis_data_locations_all_types (\\\n",
    "                                                    time_region_info, analysis_loc)\n",
    "#analysis_data_locations_all_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get History Time Stamps for All Desired Time Stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_region_info = get_history_time_stamps_all_data_types (time_region_info, \\\n",
    "                                                           max_history_to_consider, \\\n",
    "                                                           history_interval)\n",
    "#time_region_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data at All Desired Time Stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labels = json_content_extract_data['features_labels']\n",
    "features_to_read = features_labels['qois_to_read']\n",
    "labels_to_read = features_labels['labels_to_read']\n",
    "labels_ind_in_nc_file = features_labels['labels_ind_in_nc_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_read_SJSU = read_SJSU_data_desired_times (time_region_info, data_files_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame of Data at Desired Time Stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Grid Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_indices_all, grid_indices_valid, grid_indices_all_flat, grid_indices_valid_flat = \\\n",
    "    get_grid_indices_given_data_at_timestamp (data_at_timestamp, \\\n",
    "                                              x_clip_train_test, y_clip_train_test, \\\n",
    "                                              j_nevada, i_nevada, j_anchor, i_anchor, \n",
    "                                              remove_nevada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_indices_valid_reconst, grid_indices_valid_bool, valid_grid_ind_to_coord = \\\n",
    "                reconstruct_valid_grid_indices (grid_indices_valid_flat, data_at_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Create DataFrames at Desired Time Stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = dict()\n",
    "for count_ref_time, item_ref_time in enumerate(time_region_info['SJSU']):\n",
    "    timestamp_ref = [item_ref_time['RefTime']]\n",
    "    timestamps_hist = item_ref_time['HistTime']\n",
    "    #print(timestamp_ref, timestamps_hist)\n",
    "    df_dict[item_ref_time['RefTime']] = create_dataframe_FM_atm_at_timestamp (\\\n",
    "                                       timestamp_ref, timestamps_hist, data_read_SJSU, \\\n",
    "                                       history_interval, \\\n",
    "                                       grid_indices_valid_flat, valid_grid_ind_to_coord)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_at_timestamp_prep = df_dict['2020-09-04_00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_at_timestamp_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qois_to_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_identity, keys_FM, \\\n",
    "    keys_U10, keys_V10, keys_UMag10, \\\n",
    "    keys_T2, keys_RH, keys_PREC, keys_SW, \\\n",
    "                                keys_HGT = get_keys_from_extracted_data (df_at_timestamp, \\\n",
    "                                                                        train_test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_at_timestamp_prep = compute_wind_mag (df_at_timestamp_prep, keys_U10, keys_V10, keys_UMag10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_UMag10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_FM_Binary, keys_FM_MC = define_binary_and_MC_FM_labels (keys_FM)\n",
    "\n",
    "### Define Labels and Features \n",
    "keys_labels = define_labels(FM_label_type, keys_FM, keys_FM_Binary, keys_FM_MC)\n",
    "keys_features  = define_features(keys_HGT, keys_UMag10, keys_T2, keys_RH, \\\n",
    "                                 keys_PREC, keys_SW, qois_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_UMag10 = ['UMag{}'.format(U10_key[3:]) for U10_key in keys_U10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data at All Desired Time Stamps for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for timestamp_count, timestamp in enumerate(df_dict.keys()):\n",
    "    df_at_timestamp_prep = df_dict[timestamp]\n",
    "    \n",
    "    ### Get Column Names in the DataFrame\n",
    "    keys_identity, keys_FM, \\\n",
    "    keys_U10, keys_V10, keys_UMag10, \\\n",
    "    keys_T2, keys_RH, keys_PREC, keys_SW, \\\n",
    "                                keys_HGT = get_keys_from_extracted_data (df_at_timestamp, \\\n",
    "                                                                        train_test = False)\n",
    "    # Forced computation of UMag10 keys\n",
    "    keys_UMag10 = ['UMag{}'.format(U10_key[3:]) for U10_key in keys_U10]\n",
    "    \n",
    "    keys_FM_Binary, keys_FM_MC = define_binary_and_MC_FM_labels (keys_FM)\n",
    "    \n",
    "    ### Define Labels and Features \n",
    "    keys_labels = define_labels(FM_label_type, keys_FM, keys_FM_Binary, keys_FM_MC)\n",
    "    keys_features  = define_features(keys_HGT, keys_UMag10, keys_T2, keys_RH, \\\n",
    "                                     keys_PREC, keys_SW, qois_to_use)\n",
    "    \n",
    "    ### Compute New Columns or Remove Some\n",
    "    df_at_timestamp_prep = compute_wind_mag (df_at_timestamp_prep, keys_U10, keys_V10, keys_UMag10)\n",
    "    df_at_timestamp_prep = drop_wind_components (df_at_timestamp_prep, keys_U10, keys_V10)\n",
    "    '''\n",
    "    if ('UMag10' not in qois_to_read):\n",
    "        df_at_timestamp_prep = compute_wind_mag (df_at_timestamp_prep, keys_U10, keys_V10, keys_UMag10)\n",
    "    if ('UMag10' not in qois_to_read):\n",
    "        df_at_timestamp_prep = drop_wind_components (df_at_timestamp_prep, keys_U10, keys_V10)\n",
    "    '''\n",
    "    if 'VPD' in qois_derived:\n",
    "        df_at_timestamp_prep, keys_VPD = compute_VPD (df_at_timestamp_prep, keys_T2, keys_RH)\n",
    "        keys_features += keys_VPD\n",
    "    \n",
    "    if FM_label_type == 'Binary':\n",
    "        df_at_timestamp_prep = compute_binary_FM_labels(df_at_timestamp_prep, \\\n",
    "                                              keys_FM, keys_FM_Binary, FM_binary_threshold)\n",
    "    if FM_label_type == 'MultiClass':\n",
    "        df_at_timestamp_prep = compute_MC_FM_labels(df_at_timestamp_prep, \\\n",
    "                                          keys_FM, keys_FM_MC, FM_MC_levels)\n",
    "        \n",
    "    ### Split Data into Identity, Features, and Labels\n",
    "    df_at_timestamp_prep = split_data_into_groups (df_at_timestamp_prep, \\\n",
    "                                       keys_identity, keys_labels, keys_features)\n",
    "    \n",
    "    ### Save the Prepared Data\n",
    "    analysis_data_loc = analysis_data_locations_all_types['SJSU'][timestamp_count]\n",
    "    prepared_data_file_name = '{}-{}.pkl'.format(analysis_name, timestamp)\n",
    "    with open(os.path.join(analysis_data_loc, prepared_data_file_name), 'wb') as file_handle:\n",
    "        pickle.dump(df_at_timestamp_prep, file_handle)\n",
    "    print('Wrote prepared data in \"{}\" at \"{}\"'.format(prepared_data_file_name, analysis_data_loc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_at_timestamp_prep['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = generate_seed()\n",
    "random_state = init_random_generator(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_file = os.path.join(trained_model_loc, trained_model_file_name)\n",
    "model = pickle.load(open(trained_model_file, 'rb'))\n",
    "print ('\\nLoaded the ML model file at: {}\\n'.format(trained_model_file))\n",
    "print ('The model loaded is: {} \\n'.format(model))\n",
    "print ('Model params: \\n {}'.format(model.get_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Prepared Data at All Desired Time Stamps and Scale Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_region_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for timestamp_count, timestamp in enumerate(df_dict.keys()):\n",
    "    analysis_data_loc = analysis_data_locations_all_types['SJSU'][timestamp_count]\n",
    "    prepared_data_file_name = '{}-{}.pkl'.format(analysis_name, timestamp)\n",
    "\n",
    "    analysis_scatter_file_name = '{}-{}_scatter_entire.png'.format(analysis_name, timestamp)\n",
    "    analysis_cm_file_name = '{}-{}_cm_entire.png'.format(analysis_name, timestamp)\n",
    "\n",
    "    analysis_fuel_map_file_name = '{}-{}_fm_entire.png'.format(analysis_name, timestamp)\n",
    "\n",
    "    with open(os.path.join(analysis_data_loc, prepared_data_file_name), 'rb') as file_handle:\n",
    "        prepared_data = pickle.load(file_handle)\n",
    "    print('Read prepared data from \"{}\" at \"{}\"'.format(prepared_data_file_name, analysis_data_loc))\n",
    "\n",
    "    ### Deal with Features\n",
    "    features_to_use = prepared_data['features'].keys()\n",
    "    #features_to_use\n",
    "\n",
    "    ### Deal with Labels\n",
    "    if (FM_label_type == 'Regression'):\n",
    "        labels_to_use = ['FM_{}hr'.format(FM_hr)]\n",
    "    elif (FM_label_type == 'Binary'):\n",
    "        labels_to_use = ['FM_{}hr_bin'.format(FM_hr)]\n",
    "    elif (FM_label_type == 'MultiClass'):\n",
    "        labels_to_use = ['FM_{}hr_MC'.format(FM_hr)]\n",
    "    else:\n",
    "        raise ValueError('Invalid \"label_type\": {} in \"FM_labels\". \\\n",
    "                        \\nValid types are: \"Regression\", \"MultiClass\", and \"Binary\"'.format(\\\n",
    "                                                                                FM_label_type))\n",
    "    #labels_to_use\n",
    "\n",
    "    ### Extract Features and Labels from Prepared Data\n",
    "    X_gt     = prepared_data['features'][features_to_use]\n",
    "    y_gt     = prepared_data['labels'][labels_to_use]\n",
    "    j_indices = prepared_data['identity']['j_ind']\n",
    "    i_indices = prepared_data['identity']['i_ind']\n",
    "\n",
    "\n",
    "    scale_predict_plot(FM_label_type, model, model_name, scaler_type, X_gt, y_gt, \\\n",
    "                           analysis_data_loc, analysis_scatter_file_name, \\\n",
    "                           max_data_size_scatter, fig_size_x, fig_size_y, \\\n",
    "                           font_size, x_lim, \\\n",
    "                           analysis_cm_file_name,\n",
    "                           normalize_cm, \\\n",
    "                            class_labels, \\\n",
    "                           j_indices, i_indices,\\\n",
    "                           analysis_fuel_map_file_name)\n",
    "\n",
    "\n",
    "    ### Now deal with each region for the desired time stamp\n",
    "    item_ref_time = time_region_info['SJSU'][timestamp_count]\n",
    "    for count_regions, (x_clip, y_clip) in enumerate(\\\n",
    "        zip (item_ref_time['regions_x_indices'], item_ref_time['regions_y_indices'])):\n",
    "        print ('... ... Region {}:, x_clip: {}, y_clip: {}'.format(\\\n",
    "                        count_regions + 1, x_clip, y_clip))\n",
    "        region = 'region_%03d'%(count_regions + 1)\n",
    "        analysis_scatter_file_name = '{}-{}_scatter_region_{}.png'.format(analysis_name, \\\n",
    "                                                                timestamp, region)\n",
    "        analysis_cm_file_name = '{}-{}_cm_region_{}.png'.format(analysis_name,  \\\n",
    "                                                                timestamp, region)\n",
    "        analysis_fuel_map_file_name = '{}-{}_fm_region_{}.png'.format(analysis_name,  \\\n",
    "                                                                timestamp, region)\n",
    "\n",
    "        X_gt     = prepared_data['features'][features_to_use][(prepared_data['identity']['j_ind'] > y_clip[0]) &\n",
    "                           (prepared_data['identity']['j_ind'] < y_clip[1]) &\n",
    "                           (prepared_data['identity']['i_ind'] > x_clip[0]) &\n",
    "                           (prepared_data['identity']['i_ind'] < x_clip[1])]\n",
    "\n",
    "        y_gt     = prepared_data['labels'][labels_to_use][(prepared_data['identity']['j_ind'] > y_clip[0]) &\n",
    "                           (prepared_data['identity']['j_ind'] < y_clip[1]) &\n",
    "                           (prepared_data['identity']['i_ind'] > x_clip[0]) &\n",
    "                           (prepared_data['identity']['i_ind'] < x_clip[1])]\n",
    "\n",
    "        j_indices = prepared_data['identity'][(prepared_data['identity']['j_ind'] > y_clip[0]) &\n",
    "                           (prepared_data['identity']['j_ind'] < y_clip[1]) &\n",
    "                           (prepared_data['identity']['i_ind'] > x_clip[0]) &\n",
    "                           (prepared_data['identity']['i_ind'] < x_clip[1])]['j_ind']\n",
    "        i_indices = prepared_data['identity'][(prepared_data['identity']['j_ind'] > y_clip[0]) &\n",
    "                               (prepared_data['identity']['j_ind'] < y_clip[1]) &\n",
    "                               (prepared_data['identity']['i_ind'] > x_clip[0]) &\n",
    "                               (prepared_data['identity']['i_ind'] < x_clip[1])]['i_ind']\n",
    "\n",
    "        if (len(X_gt) > 0):\n",
    "            scale_predict_plot(FM_label_type, model, model_name, scaler_type, X_gt, y_gt, \\\n",
    "                               analysis_data_loc, analysis_scatter_file_name, \\\n",
    "                               max_data_size_scatter, fig_size_x, fig_size_y, \\\n",
    "                               font_size, x_lim, \\\n",
    "                               analysis_cm_file_name,\n",
    "                               normalize_cm, \\\n",
    "                                class_labels, \\\n",
    "                               j_indices, i_indices,\\\n",
    "                               analysis_fuel_map_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global End Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_final_memory = process.memory_info().rss\n",
    "global_end_time = timer()\n",
    "global_memory_consumed = global_final_memory - global_initial_memory\n",
    "print('Total memory consumed: {:.3f} MB'.format(global_memory_consumed/(1024*1024)))\n",
    "print('Total computing time: {:.3f} s'.format(global_end_time - global_start_time))\n",
    "print('=========================================================================')\n",
    "print(\"SUCCESS: Done Training and Testing of Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_ml_conda",
   "language": "python",
   "name": "py3_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
