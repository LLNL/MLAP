{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118e46f2",
   "metadata": {},
   "source": [
    "## Convert this notebook to executable python script using:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a8cc0",
   "metadata": {},
   "source": [
    "- jupyter nbconvert --to python EvaluateTrainedModels.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd880a5b",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from datetime import date, datetime, timedelta, time\n",
    "from timeit import default_timer as timer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrainModel_Helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a715c75",
   "metadata": {},
   "source": [
    "# Read the Input JSON File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaf988",
   "metadata": {},
   "source": [
    "### Input file name when using jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df768d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_eval_models = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Eval/json_eval_001.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd32a84",
   "metadata": {},
   "source": [
    "### Input file name when using python script on command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ef775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_file_eval_models = sys.argv[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614f8011",
   "metadata": {},
   "source": [
    "### Load the JSON file for evaluating trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for evaluating trained models: \\n {}'.format(json_file_eval_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_eval_models) as json_file_handle:\n",
    "    json_content_eval_models = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_eval_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fef746",
   "metadata": {},
   "source": [
    "# Evaluation Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_count = json_content_eval_models['evaluation']['count']\n",
    "identifier_text = json_content_eval_models['evaluation']['identifier_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d22b6",
   "metadata": {},
   "source": [
    "# Simulation Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dir = json_content_eval_models['paths']['sim_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0df73b",
   "metadata": {},
   "source": [
    "# Paths and File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model_base_loc = json_content_eval_models['paths']['eval_model_base_loc']\n",
    "eval_model_name = 'eval_%03d_%s'%(eval_count, identifier_text)\n",
    "eval_model_loc = os.path.join(eval_model_base_loc, eval_model_name)\n",
    "os.system('mkdir -p %s'%eval_model_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1cc6a",
   "metadata": {},
   "source": [
    "# `json` Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ed949",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_extract_base = json_content_eval_models['paths']['json_extract_base']\n",
    "json_prep_base = json_content_eval_models['paths']['json_prep_base']\n",
    "json_train_base = json_content_eval_models['paths']['json_train_base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_extract_base = os.path.join(sim_dir, json_extract_base)\n",
    "json_prep_base = os.path.join(sim_dir, json_prep_base)\n",
    "json_train_base = os.path.join(sim_dir, json_train_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b1a119",
   "metadata": {},
   "source": [
    "# Collect Metrics of Desired Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f5692",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_options = json_content_eval_models['collection_options']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_extract_counts = collection_options['json_extract_counts']\n",
    "json_prep_train_maps = collection_options['json_prep_train_maps']\n",
    "FM_label_type = collection_options['FM_label_type']\n",
    "metric_names = collection_options['metric_names']\n",
    "metric_on_sets = collection_options['metric_on_sets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bfe46f",
   "metadata": {},
   "source": [
    "## Create label and train pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98232959",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train_pair, col_names = create_label_train_pair (json_prep_train_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_extract_counts\n",
    "#label_train_pair\n",
    "#col_names\n",
    "#metric_names\n",
    "#metric_on_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7061fd",
   "metadata": {},
   "source": [
    "## Create data definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_defn = create_data_definition (json_extract_base, json_extract_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_defn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_defn.to_csv(os.path.join(eval_model_loc, eval_model_name+'_data_defn.csv'), \\\n",
    "                                   index=False, float_format = '%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a3ca0",
   "metadata": {},
   "source": [
    "## Collect evaluation metrics and plot them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c636f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_name in metric_names:\n",
    "    for metric_on_set in metric_on_sets:\n",
    "        df_metrics = gather_metrics_for_all_label_train_pairs (\\\n",
    "                                                  label_train_pair, col_names, \\\n",
    "                                                  json_train_base, json_extract_counts, \\\n",
    "                                                  FM_label_type, metric_name, metric_on_set, \\\n",
    "                                                  eval_model_loc, eval_model_name)\n",
    "        #print (df_metrics)       \n",
    "\n",
    "        create_bar_plots (df_metrics, FM_label_type, metric_name, metric_on_set, \\\n",
    "                                           eval_model_loc, eval_model_name)\n",
    "        create_heatmap (df_metrics, FM_label_type, metric_name, metric_on_set, \\\n",
    "                                           eval_model_loc, eval_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3123bb27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_ml_conda",
   "language": "python",
   "name": "py3_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
