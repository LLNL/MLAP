{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as path\n",
    "import psutil\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "#plt.style.use('seaborn-white')\n",
    "from datetime import date, datetime, timedelta, time\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Extract_DFM_Reanalysis_Data_Helper import *\n",
    "from Prepare_TrainTestFire_Data_Helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Start Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start_time = timer()\n",
    "process = psutil.Process(os.getpid())\n",
    "global_initial_memory = process.memory_info().rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables to be Used for Preparing Train, Test, and Fire Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current data set params\n",
    "data_set_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define FM Threshold etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_binary_threshold = 0.03\n",
    "FM_multiclass_levels = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and File Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRF data set location and the extracted data set location\n",
    "extracted_data_base_loc = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/SJSU/01_WRF_Nelson_Data_Extracted'\n",
    "prepared_data_base_loc = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/SJSU/02_TrainTestFire_Data_Prepared'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet Specific (Train, Test, Fire Data Extracted from WRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'data_train_test_extracted_%02d'%(data_set_count)\n",
    "extracted_data_loc = os.path.join(extracted_data_base_loc, data_set_name)\n",
    "extracted_data_file_name = '{}_df.pkl'.format(data_set_name)\n",
    "\n",
    "fire_data_set_name = 'data_fire_extracted_%02d'%(data_set_count)\n",
    "fire_data_loc = os.path.join(extracted_data_base_loc, fire_data_set_name)\n",
    "fire_data_file_name = '{}.pkl'.format(fire_data_set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet Specific (Train, Test, Fire Prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data_set_name = 'data_prepared_%02d'%(data_set_count)\n",
    "\n",
    "prepared_data_loc = os.path.join(prepared_data_base_loc, prepared_data_set_name)\n",
    "os.system('mkdir -p %s'%prepared_data_loc)\n",
    "\n",
    "prepared_data_file_name = '{}.pkl'.format(prepared_data_set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = generate_seed()\n",
    "random_state = init_random_generator(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Pickled Extracted Data (Train, Test, Fire) from WRF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Train/Test Data Saved in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt_extracted = pd.read_pickle(os.path.join(extracted_data_loc, extracted_data_file_name))\n",
    "#df_tt_extracted[998:1002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Fire Data Saved in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read fire data from \"data_fire_extracted_01.pkl\" at \"/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/SJSU/01_WRF_Nelson_Data_Extracted/data_fire_extracted_01\"\n"
     ]
    }
   ],
   "source": [
    "fire_data_file_handle = open(os.path.join(fire_data_loc, fire_data_file_name), 'rb')\n",
    "fire_data_extracted = pickle.load(fire_data_file_handle)\n",
    "fire_data_file_handle.close()\n",
    "print('Read fire data from \"{}\" at \"{}\"'.format(fire_data_file_name, fire_data_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fire_data_extracted['Woosley'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure The Train/test and Fire Data Have the Same Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_extracted.keys() == fire_data_extracted['Woosley'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Column Names in the Train, Test, and Fire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted = df_tt_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "keys_identity, keys_FM, \\\n",
    "keys_U10, keys_V10, U10Mag, \\\n",
    "keys_T2, keys_RH, keys_PREC, keys_SW, \\\n",
    "                            keys_HGT = get_keys_from_extracted_data (df_tt_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global End Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory consumed: 312.180 MB\n",
      "Total computing time: 0.899 s\n",
      "=========================================================================\n",
      "SUCCESS: Done Extraction of Data\n"
     ]
    }
   ],
   "source": [
    "global_final_memory = process.memory_info().rss\n",
    "global_end_time = timer()\n",
    "global_memory_consumed = global_final_memory - global_initial_memory\n",
    "print('Total memory consumed: {:.3f} MB'.format(global_memory_consumed/(1024*1024)))\n",
    "print('Total computing time: {:.3f} s'.format(global_end_time - global_start_time))\n",
    "print('=========================================================================')\n",
    "print(\"SUCCESS: Done Extraction of Data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_ml_conda",
   "language": "python",
   "name": "py3_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
