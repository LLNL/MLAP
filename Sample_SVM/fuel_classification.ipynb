{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1446478/197202962.py:11: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%pylab inline\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#from IPython import embed\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Process Excel Sheets (Organized by Fuel Type and Labeled as Burnable or Unburnable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_path = 'raw_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the processed excel sheet with alerts and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excel_processed = pd.ExcelFile(os.path.join(data_base_path, 'GroundTruth_FuelTypes13_Labeled.xlsx'))\n",
    "excel_processed = pd.ExcelFile(os.path.join(data_base_path, 'GroundTruth_FuelTypes05_Labeled.xlsx'))\n",
    "#excel_processed = pd.ExcelFile(os.path.join(data_base_path, 'GroundTruth_FuelMoisture.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_to_df_map_read = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_to_use = ['feature01', 'feature02', 'feature03', 'feature04','feature05', 'feature06', 'feature07']\n",
    "features_to_use = ['DN1', 'DN2', 'DN3', 'DN4']\n",
    "#features_to_use = ['WS_t1', 'WS_t2', 'WS_tn', 'T_t1', 'T_t2', 'T_tn', 'QoI_t1', 'QoI_t2', 'QoI_tn']\n",
    "#features_to_use = ['WS_t1', 'WS_t2', 'T_t1', 'T_t2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in excel_processed.sheet_names:\n",
    "    df_read = pd.DataFrame(pd.read_excel(excel_processed, sheet))\n",
    "    if sheet == 'Summary':\n",
    "        sheet_to_df_map_read[sheet] = df_read\n",
    "    else:            \n",
    "        sheet_to_df_map_read[sheet] = df_read[['SheetName'] + features_to_use + ['Label']]\n",
    "del sheet_to_df_map_read['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Fuel01', 'Fuel02', 'Fuel03', 'Fuel04', 'Fuel05'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet_to_df_map_read.keys()\n",
    "#sheet_to_df_map_read['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sheet_to_df_map_read['FuelMoisture'][features_to_use + ['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SheetName</th>\n",
       "      <th>DN1</th>\n",
       "      <th>DN2</th>\n",
       "      <th>DN3</th>\n",
       "      <th>DN4</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuel05</td>\n",
       "      <td>11.102183</td>\n",
       "      <td>4.29008</td>\n",
       "      <td>9.37405</td>\n",
       "      <td>-77.694054</td>\n",
       "      <td>Fuel05_Unburnable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuel05</td>\n",
       "      <td>11.876525</td>\n",
       "      <td>10.73280</td>\n",
       "      <td>3.78626</td>\n",
       "      <td>3.165404</td>\n",
       "      <td>Fuel05_Unburnable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuel05</td>\n",
       "      <td>7.873579</td>\n",
       "      <td>8.04580</td>\n",
       "      <td>14.06110</td>\n",
       "      <td>-59.000118</td>\n",
       "      <td>Fuel05_Unburnable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuel05</td>\n",
       "      <td>7.805673</td>\n",
       "      <td>6.41221</td>\n",
       "      <td>7.64885</td>\n",
       "      <td>-70.938026</td>\n",
       "      <td>Fuel05_Unburnable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuel05</td>\n",
       "      <td>10.082099</td>\n",
       "      <td>8.39695</td>\n",
       "      <td>19.26720</td>\n",
       "      <td>69.736328</td>\n",
       "      <td>Fuel05_Unburnable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SheetName        DN1       DN2       DN3        DN4              Label\n",
       "0    Fuel05  11.102183   4.29008   9.37405 -77.694054  Fuel05_Unburnable\n",
       "1    Fuel05  11.876525  10.73280   3.78626   3.165404  Fuel05_Unburnable\n",
       "2    Fuel05   7.873579   8.04580  14.06110 -59.000118  Fuel05_Unburnable\n",
       "3    Fuel05   7.805673   6.41221   7.64885 -70.938026  Fuel05_Unburnable\n",
       "4    Fuel05  10.082099   8.39695  19.26720  69.736328  Fuel05_Unburnable"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet_to_df_map_read['Fuel05'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = ['feature01', 'feature02', 'feature03', 'feature04','feature05', 'feature06', 'feature07']\n",
    "features = ['DN1', 'DN2', 'DN3', 'DN4']\n",
    "labels = ['Label', 'NewLabel', 'SheetName']\n",
    "cols = labels + features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Label sheets and combine and prune them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_to_df_map = re_label_data(sheet_to_df_map_read)\n",
    "df_combined = combine_df_sheets(sheet_to_df_map, sorted(sheet_to_df_map.keys()), cols)\n",
    "df_combined_orig = df_combined\n",
    "len(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_combined)\n",
    "#df_combined.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, average_precision_score\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work with Multiple Features of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = ['feature01', 'feature02', 'feature03', 'feature04','feature05', 'feature06', 'feature07']\n",
    "features = ['DN1', 'DN2', 'DN3', 'DN4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Features and Labels for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_features_labels(df_combined, features_to_use)\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sheets_train, sheets_test, labels_train, labels_test = split_labels_sheets(labels_train, labels_test)\n",
    "len(features_train), len(features_test), len(labels_train), len(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## SVM #################################\n",
    "# Training Time is significantly more with large values of C\n",
    "clf = SVC(kernel=\"linear\", class_weight = \"balanced\") #class_weight\n",
    "# Try RBF etc., gamma term, epsilon, C\n",
    "# Grid search to optimize parameters\n",
    "# Semantic segmentation of pixels\n",
    "# Try Random Forest\n",
    "# Google earth Engine for satellite images in addition to QGIS\n",
    "\n",
    "### fit the classifier on the training features and labels\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print (\"Training Time:\", round(time()-t0, 3), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Model to a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "'svm_N1205_T080_C1 --> svm_N(number of total data)_T(percentage for training)_C(model parameter in model constructor, default 1)'\n",
    "svm_model_file = 'models_trained/svm_N1205_T080_C1'\n",
    "pickle.dump(clf, open(svm_model_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load the Model from a File (A template...use specific model for specific pupose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predict on the Train Data itself using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('models_trained/svm_N1205_T080_C1', 'rb'))\n",
    "t1 = time()\n",
    "labels_svm_pred = clf.predict(features_train)\n",
    "print (\"Prediction Time:\", round(time()-t1, 3), \"s\")\n",
    "#print ('labels_svm_pred: {}'.format(labels_svm_pred))\n",
    "\n",
    "accuracy = accuracy_score(labels_svm_pred, labels_train)\n",
    "print('Accuracy Score: {}'.format(accuracy))\n",
    "\n",
    "conf_mat = confusion_matrix(labels_train, labels_svm_pred, labels = [1, 0])\n",
    "print('Confusion Matrix: \\n{}'.format(conf_mat))\n",
    "\n",
    "print('Classification Report: \\n')\n",
    "print(classification_report(labels_train, labels_svm_pred, labels=[1, 0]))\n",
    "\n",
    "average_precision = average_precision_score(labels_train, labels_svm_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the Test Data using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### use the trained classifier to predict labels for the test features using SVM predict\n",
    "clf = pickle.load(open('models_trained/svm_N1205_T080_C1', 'rb'))\n",
    "t1 = time()\n",
    "labels_svm_pred = clf.predict(features_test)\n",
    "print (\"Prediction Time:\", round(time()-t1, 3), \"s\")\n",
    "#print ('labels_svm_pred: {}'.format(labels_svm_pred))\n",
    "\n",
    "accuracy = accuracy_score(labels_svm_pred, labels_test)\n",
    "print('Accuracy Score: {}'.format(accuracy))\n",
    "\n",
    "conf_mat = confusion_matrix(labels_test, labels_svm_pred, labels = [1, 0])\n",
    "print('Confusion Matrix: \\n{}'.format(conf_mat))\n",
    "\n",
    "print('Classification Report: \\n')\n",
    "print(classification_report(labels_test, labels_svm_pred, labels=[1, 0]))\n",
    "\n",
    "average_precision = average_precision_score(labels_test, labels_svm_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "\"\"\"\n",
    "precision, recall, thresholds = precision_recall_curve(labels_test, pred)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with Feature Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_to_use\n",
    "for i in range(len(features)):\n",
    "    for j in range(i+1, len(features)):\n",
    "        #print('i: {}, j: {}'.format(i, j))\n",
    "        v1 = features[i]\n",
    "        v2 = features[j]\n",
    "        print('---- v1: {}, v2: {} ------'.format(v1, v2))\n",
    "        X, y = get_features_labels(df_combined, [v1, v2])\n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "        sheets_train, sheets_test, labels_train, labels_test = split_labels_sheets(labels_train, labels_test)\n",
    "        \n",
    "        #len(features_train), len(features_test)\n",
    "        clf = SVC(kernel=\"rbf\", class_weight = \"balanced\") #class_weight\n",
    "        \n",
    "        ### fit the classifier on the training features and labels\n",
    "        t0 = time()\n",
    "        clf.fit(features_train, labels_train)\n",
    "        print (\"Training Time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "        ### use the trained classifier to predict labels for the test features\n",
    "        t1 = time()\n",
    "        pred = clf.predict(features_test)\n",
    "        #print (\"Prediction Time:\", round(time()-t1, 3), \"s\")\n",
    "        #print ('pred: {}'.format(pred))\n",
    "\n",
    "        accuracy = accuracy_score(pred, labels_test)\n",
    "        #print('Accuracy Score: {}'.format(accuracy))\n",
    "        \n",
    "        plot_scatter_svm (clf, features_test, labels_test, v1, v2, accuracy, plot_base_dir = 'plots', scatter_dir = 'SVM')\n",
    "        plot_scatter_arr (features_test, labels_test, v1, v2, accuracy, plot_base_dir = 'plots', scatter_dir = 'scatter/test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Statistics/ Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_for_hist = features_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_dfmap_combined(sheet_to_df_map, ['Fuel01', 'Fuel02', 'Fuel03','Fuel04'],\n",
    "                         col_for_hist, 'histogram/Burnable', plot_base_dir = 'plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_dfmap_combined(sheet_to_df_map, ['Fuel05'],\n",
    "                         col_for_hist, 'histogram/Unburnable', plot_base_dir = 'plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnable_sheets = ['Fuel01', 'Fuel02', 'Fuel03','Fuel04']\n",
    "unburnable_sheets = ['Fuel05']\n",
    "v_list = features_to_use\n",
    "for i in range(len(v_list)):\n",
    "    for j in range(i+1, len(v_list)):\n",
    "        #print('i: {}, j: {}'.format(i, j))\n",
    "        plot_scatter_df(sheet_to_df_map, burnable_sheets, unburnable_sheets, v_list[i], v_list[j], 'plots', 'scatter/all_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_ml] *",
   "language": "python",
   "name": "conda-env-py3_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
