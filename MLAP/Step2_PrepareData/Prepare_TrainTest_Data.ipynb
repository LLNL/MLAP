{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert this notebook to executable python script using:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- jupyter nbconvert --to python Prepare_TrainTest_Data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as path\n",
    "import psutil\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pickle\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from datetime import date, datetime, timedelta, time\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_running_file_dir = sys.path[0]\n",
    "current_running_file_par = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, os.path.join(current_running_file_par, 'Step1_ExtractData'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('current_running_file_dir:', current_running_file_dir)\n",
    "#print('current_running_file_par:', current_running_file_par)\n",
    "#print('PATH: ', sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Extract_DFM_Data_Helper import *\n",
    "from Prepare_TrainTest_Data_Helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Start Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start_time = timer()\n",
    "process = psutil.Process(os.getpid())\n",
    "global_initial_memory = process.memory_info().rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Input JSON File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file name when using jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_extract_data = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Extract/json_extract_data_000.json'\n",
    "json_file_prep_data    = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Prep/json_prep_data_label_007.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file name when using python script on command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_file_extract_data = sys.argv[1]\n",
    "#json_file_prep_data = sys.argv[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the JSON file for extracting data: \n",
      " /p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Extract/json_extract_data_000.json\n"
     ]
    }
   ],
   "source": [
    "print('Loading the JSON file for extracting data: \\n {}'.format(json_file_extract_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_extract_data) as json_file_handle:\n",
    "    json_content_extract_data = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_extract_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the JSON file for preparing data: \n",
      " /p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/InputJson/Prep/json_prep_data_label_007.json\n"
     ]
    }
   ],
   "source": [
    "print('Loading the JSON file for preparing data: \\n {}'.format(json_file_prep_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_prep_data) as json_file_handle:\n",
    "    json_content_prep_data = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_prep_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables to be Used for Preparing Train and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current data set params\n",
    "data_set_count = json_content_extract_data['data_set_defn']['data_set_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labels = json_content_extract_data['features_labels']\n",
    "features_to_read = features_labels['features_to_read']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Label, FM Threshold etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = json_content_prep_data['label_defn']['label_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_labels = json_content_prep_data['FM_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_label_type = FM_labels['label_type']\n",
    "\n",
    "if (FM_label_type == 'Binary'):\n",
    "    FM_binary_threshold = FM_labels['FM_binary_threshold']\n",
    "if (FM_label_type == 'MultiClass'):\n",
    "    FM_MC_levels = FM_labels['FM_MC_levels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qois_to_use = json_content_prep_data['features']['qois_to_use']\n",
    "qois_derived = json_content_prep_data['features']['qois_derived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_data = json_content_prep_data['prune_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and File Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRF data set location and the extracted data set location\n",
    "extracted_data_base_loc = json_content_extract_data['paths']['extracted_data_base_loc']\n",
    "prepared_data_base_loc  = json_content_prep_data['paths']['prepared_data_base_loc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet Specific (Train and Test Data Extracted from WRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'data_train_test_extracted_%03d'%(data_set_count)\n",
    "extracted_data_loc = os.path.join(extracted_data_base_loc, data_set_name)\n",
    "extracted_data_file_name = '{}_df.pkl'.format(data_set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet and Label Specific (Train and Test Data Prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data_set_name = 'dataset_%03d_label_%03d_%s'%(data_set_count, label_count, FM_label_type)\n",
    "\n",
    "prepared_data_loc = os.path.join(prepared_data_base_loc, prepared_data_set_name)\n",
    "os.system('mkdir -p %s'%prepared_data_loc)\n",
    "\n",
    "prepared_data_file_name = '{}.pkl'.format(prepared_data_set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = generate_seed()\n",
    "random_state = init_random_generator(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Pickled Extracted Data (Train, Test) from WRF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Train/Test Data Saved in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================\n",
      "MODULE Name: \"load_pickled_data\"\n",
      "\n",
      "Process in the module(): psutil.Process(pid=184263, name='python3', status='running', started='14:16:09')\n",
      "\n",
      "Loading data from file:\n",
      " ... data_train_test_extracted_000_df.pkl \n",
      " ... at: /p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/01_WRF_Nelson_Data_Extracted/data_train_test_extracted_000\n",
      "\n",
      "Module memory consumed: 14.906 MB\n",
      "Module computing time: 0.059 s\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "df_tt_prep = load_pickled_data (extracted_data_loc, extracted_data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep['PRECIP[-8hr]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_tt_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune Extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt_prep = prune_desired_data (df_tt_prep, prune_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce The Size of Extracted Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing data size (float64 to float16, int64 to int32)\n"
     ]
    }
   ],
   "source": [
    "df_tt_prep = reduce_data_size (df_tt_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Column Names in the Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_identity, keys_FM, \\\n",
    "keys_U10, keys_V10, keys_UMag10, \\\n",
    "keys_T2, keys_RH, keys_PREC, keys_SW, \\\n",
    "                            keys_HGT = get_keys_from_extracted_data (df_tt_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys_U10, keys_V10, keys_UMag10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_FM_Binary, keys_FM_MC = define_binary_and_MC_FM_labels (keys_FM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Groups of Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_labels = define_labels(FM_label_type, keys_FM, keys_FM_Binary, keys_FM_MC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys_FM_MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_features  = define_features(keys_HGT, keys_UMag10, keys_T2, keys_RH, keys_PREC, keys_SW, \\\n",
    "                   qois_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Compute New Columns or Remove Some"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Wind Magnitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_to_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('UMag10' not in features_to_read):\n",
    "    df_tt_prep = compute_wind_mag (df_tt_prep, keys_U10, keys_V10, keys_UMag10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep[keys_U10 + keys_V10 + keys_UMag10]\n",
    "#df_tt_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Wind Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('UMag10' not in features_to_read):\n",
    "    df_tt_prep = drop_wind_components (df_tt_prep, keys_U10, keys_V10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep[keys_UMag10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute VPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'VPD' in qois_derived:\n",
    "    df_tt_prep, keys_VPD = compute_VPD (df_tt_prep, keys_T2, keys_RH)\n",
    "    keys_features += keys_VPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Vapor Pressure Deficit (VPD) from T2 and RH\n"
     ]
    }
   ],
   "source": [
    "print ('Computing Vapor Pressure Deficit (VPD) from T2 and RH')\n",
    "keys_VPD_s = []\n",
    "keys_VPD = []\n",
    "for T2_key, RH_key in zip(keys_T2, keys_RH):\n",
    "    assert T2_key[2:] == RH_key[2:]\n",
    "    VPD_s_key = 'VPD_s{}'.format(T2_key[2:])\n",
    "    VPD_key = 'VPD{}'.format(T2_key[2:])\n",
    "    keys_VPD_s.append(VPD_s_key)\n",
    "    keys_VPD.append(VPD_key)\n",
    "    \n",
    "    \n",
    "    df_tt_prep[VPD_key] = df_tt_prep[T2_key]*0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['VPD[-8hr]', 'VPD[-6hr]', 'VPD[-4hr]', 'VPD[-2hr]'],\n",
       " ['VPD_s[-8hr]', 'VPD_s[-6hr]', 'VPD_s[-4hr]', 'VPD_s[-2hr]'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_VPD, keys_VPD_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HGT</th>\n",
       "      <th>VPD[-8hr]</th>\n",
       "      <th>VPD[-6hr]</th>\n",
       "      <th>VPD[-4hr]</th>\n",
       "      <th>VPD[-2hr]</th>\n",
       "      <th>T2[-8hr]</th>\n",
       "      <th>T2[-6hr]</th>\n",
       "      <th>T2[-4hr]</th>\n",
       "      <th>T2[-2hr]</th>\n",
       "      <th>RH[-8hr]</th>\n",
       "      <th>RH[-6hr]</th>\n",
       "      <th>RH[-4hr]</th>\n",
       "      <th>RH[-2hr]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>677.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.25</td>\n",
       "      <td>283.50</td>\n",
       "      <td>286.00</td>\n",
       "      <td>287.25</td>\n",
       "      <td>61.90625</td>\n",
       "      <td>43.93750</td>\n",
       "      <td>38.593750</td>\n",
       "      <td>32.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.25</td>\n",
       "      <td>287.75</td>\n",
       "      <td>290.50</td>\n",
       "      <td>292.50</td>\n",
       "      <td>65.75000</td>\n",
       "      <td>53.46875</td>\n",
       "      <td>36.468750</td>\n",
       "      <td>24.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1382.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.00</td>\n",
       "      <td>277.75</td>\n",
       "      <td>279.25</td>\n",
       "      <td>280.50</td>\n",
       "      <td>71.56250</td>\n",
       "      <td>52.84375</td>\n",
       "      <td>47.625000</td>\n",
       "      <td>35.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1732.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273.50</td>\n",
       "      <td>275.50</td>\n",
       "      <td>277.50</td>\n",
       "      <td>278.75</td>\n",
       "      <td>60.15625</td>\n",
       "      <td>52.09375</td>\n",
       "      <td>39.968750</td>\n",
       "      <td>30.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1540.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.50</td>\n",
       "      <td>278.75</td>\n",
       "      <td>281.00</td>\n",
       "      <td>282.50</td>\n",
       "      <td>52.34375</td>\n",
       "      <td>39.50000</td>\n",
       "      <td>25.984375</td>\n",
       "      <td>20.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>860.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.00</td>\n",
       "      <td>280.25</td>\n",
       "      <td>279.25</td>\n",
       "      <td>280.50</td>\n",
       "      <td>35.96875</td>\n",
       "      <td>64.93750</td>\n",
       "      <td>58.218750</td>\n",
       "      <td>49.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>1441.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273.75</td>\n",
       "      <td>271.75</td>\n",
       "      <td>270.00</td>\n",
       "      <td>271.00</td>\n",
       "      <td>82.68750</td>\n",
       "      <td>81.25000</td>\n",
       "      <td>85.750000</td>\n",
       "      <td>81.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>1713.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.75</td>\n",
       "      <td>272.75</td>\n",
       "      <td>272.00</td>\n",
       "      <td>273.00</td>\n",
       "      <td>60.71875</td>\n",
       "      <td>91.56250</td>\n",
       "      <td>91.812500</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>170.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.00</td>\n",
       "      <td>283.00</td>\n",
       "      <td>282.25</td>\n",
       "      <td>280.50</td>\n",
       "      <td>64.31250</td>\n",
       "      <td>81.50000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>89.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>2064.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.25</td>\n",
       "      <td>269.25</td>\n",
       "      <td>269.00</td>\n",
       "      <td>269.25</td>\n",
       "      <td>46.53125</td>\n",
       "      <td>46.40625</td>\n",
       "      <td>51.031250</td>\n",
       "      <td>54.406250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7143 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           HGT  VPD[-8hr]  VPD[-6hr]  VPD[-4hr]  VPD[-2hr]  T2[-8hr]  \\\n",
       "0      677.500        0.0        0.0        0.0        0.0    280.25   \n",
       "1       78.625        0.0        0.0        0.0        0.0    285.25   \n",
       "2     1382.000        0.0        0.0        0.0        0.0    275.00   \n",
       "3     1732.000        0.0        0.0        0.0        0.0    273.50   \n",
       "4     1540.000        0.0        0.0        0.0        0.0    276.50   \n",
       "...        ...        ...        ...        ...        ...       ...   \n",
       "7495   860.500        0.0        0.0        0.0        0.0    285.00   \n",
       "7496  1441.000        0.0        0.0        0.0        0.0    273.75   \n",
       "7497  1713.000        0.0        0.0        0.0        0.0    278.75   \n",
       "7498   170.875        0.0        0.0        0.0        0.0    287.00   \n",
       "7499  2064.000        0.0        0.0        0.0        0.0    270.25   \n",
       "\n",
       "      T2[-6hr]  T2[-4hr]  T2[-2hr]  RH[-8hr]  RH[-6hr]   RH[-4hr]   RH[-2hr]  \n",
       "0       283.50    286.00    287.25  61.90625  43.93750  38.593750  32.031250  \n",
       "1       287.75    290.50    292.50  65.75000  53.46875  36.468750  24.078125  \n",
       "2       277.75    279.25    280.50  71.56250  52.84375  47.625000  35.875000  \n",
       "3       275.50    277.50    278.75  60.15625  52.09375  39.968750  30.140625  \n",
       "4       278.75    281.00    282.50  52.34375  39.50000  25.984375  20.640625  \n",
       "...        ...       ...       ...       ...       ...        ...        ...  \n",
       "7495    280.25    279.25    280.50  35.96875  64.93750  58.218750  49.031250  \n",
       "7496    271.75    270.00    271.00  82.68750  81.25000  85.750000  81.812500  \n",
       "7497    272.75    272.00    273.00  60.71875  91.56250  91.812500  76.000000  \n",
       "7498    283.00    282.25    280.50  64.31250  81.50000  80.000000  89.312500  \n",
       "7499    269.25    269.00    269.25  46.53125  46.40625  51.031250  54.406250  \n",
       "\n",
       "[7143 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tt_prep[keys_HGT + keys_VPD + keys_T2 + keys_RH]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Binary FM Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FM_label_type == 'Binary':\n",
    "    df_tt_prep = compute_binary_FM_labels(df_tt_prep, \\\n",
    "                                          keys_FM, keys_FM_Binary, FM_binary_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_tt_prep.keys())\n",
    "#df_tt_prep[keys_FM + keys_FM_Binary].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep[keys_FM + keys_FM_Binary][985:995]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MC FM Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FM_label_type == 'MultiClass':\n",
    "    df_tt_prep = compute_MC_FM_labels(df_tt_prep, \\\n",
    "                                      keys_FM, keys_FM_MC, FM_MC_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep[keys_FM + keys_FM_MC].dtypes\n",
    "#df_tt_prep[keys_FM + keys_FM_MC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot FM Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_hr = json_content_prep_data['qoi_to_plot']['FM_hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_FM_labels (df_tt_prep, FM_label_type, FM_hr, \\\n",
    "                prepared_data_set_name, prepared_data_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Identity, Features, and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tt_prep = split_data_into_groups (df_tt_prep, \\\n",
    "                                       keys_identity, keys_labels, keys_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = data_tt_prep\n",
    "with open(os.path.join(prepared_data_loc, prepared_data_file_name), 'wb') as file_handle:\n",
    "    pickle.dump(prepared_data, file_handle)\n",
    "print('Wrote prepared data in \"{}\" at \"{}\"'.format(prepared_data_file_name, prepared_data_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Test The Prepared Data Saved in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data_read = load_pickled_data (prepared_data_loc, prepared_data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(prepared_data_loc, prepared_data_file_name), 'rb') as file_handle:\n",
    " #   prepared_data_read = pickle.load(file_handle)\n",
    "print('Read prepared data from \"{}\" at \"{}\"'.format(prepared_data_file_name, prepared_data_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_data_read['identity']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_data_read['labels'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_data_read['labels'][prepared_data_read['labels']['FM_10hr_bin'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_data_read['features'].dtypes\n",
    "#prepared_data_read['features'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_data_read['features']['UMag10[-8hr]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global End Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_final_memory = process.memory_info().rss\n",
    "global_end_time = timer()\n",
    "global_memory_consumed = global_final_memory - global_initial_memory\n",
    "print('Total memory consumed: {:.3f} MB'.format(global_memory_consumed/(1024*1024)))\n",
    "print('Total computing time: {:.3f} s'.format(global_end_time - global_start_time))\n",
    "print('=========================================================================')\n",
    "print(\"SUCCESS: Done Preparation of Data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_ml_conda",
   "language": "python",
   "name": "py3_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
