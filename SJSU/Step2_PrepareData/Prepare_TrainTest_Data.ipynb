{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert this notebook to executable python script using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter nbconvert --to python Prepare_TrainTest_Data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as path\n",
    "import psutil\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pickle\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from datetime import date, datetime, timedelta, time\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_running_file_dir = sys.path[0]\n",
    "current_running_file_par = '/'.join(sys.path[0].split('/')[:-1])\n",
    "sys.path.insert(0, os.path.join(current_running_file_par, 'Step1_ExtractData'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('current_running_file_dir:', current_running_file_dir)\n",
    "print('current_running_file_par:', current_running_file_par)\n",
    "print('PATH: ', sys.path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Extract_DFM_Data_Helper import *\n",
    "from Prepare_TrainTest_Data_Helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Start Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start_time = timer()\n",
    "process = psutil.Process(os.getpid())\n",
    "global_initial_memory = process.memory_info().rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Input JSON File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file name when using jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_extract_data = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/01_WRF_Nelson_Data_Extracted/InputJsonFiles/json_extract_data_000.json'\n",
    "json_file_prep_data    = '/p/lustre2/jha3/Wildfire/Wildfire_LDRD_SI/02_TrainTest_Data_Prepared/InputJsonFiles/json_prep_data_label_000.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file name when using python script on command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_file_extract_data = sys.argv[1]\n",
    "#json_file_prep_data = sys.argv[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for extracting data: \\n {}'.format(json_file_extract_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_extract_data) as json_file_handle:\n",
    "    json_content_extract_data = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_extract_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the JSON file for preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading the JSON file for preparing data: \\n {}'.format(json_file_prep_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_prep_data) as json_file_handle:\n",
    "    json_content_prep_data = json.load(json_file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_content_prep_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables to be Used for Preparing Train and Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current data set params\n",
    "data_set_count = json_content_extract_data['data_set_defn']['data_set_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Label, FM Threshold etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = json_content_prep_data['label_defn']['label_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_labels = json_content_prep_data['FM_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_label_type = FM_labels['label_type']\n",
    "\n",
    "if (FM_label_type == 'Binary'):\n",
    "    FM_binary_threshold = FM_labels['FM_binary_threshold']\n",
    "if (FM_label_type == 'MultiClass'):\n",
    "    FM_MC_levels = FM_labels['FM_MC_levels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and File Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRF data set location and the extracted data set location\n",
    "extracted_data_base_loc = json_content_extract_data['paths']['extracted_data_base_loc']\n",
    "prepared_data_base_loc  = json_content_prep_data['paths']['prepared_data_base_loc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet Specific (Train and Test Data Extracted from WRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'data_train_test_extracted_%02d'%(data_set_count)\n",
    "extracted_data_loc = os.path.join(extracted_data_base_loc, data_set_name)\n",
    "extracted_data_file_name = '{}_df.pkl'.format(data_set_name)\n",
    "'''\n",
    "fire_data_set_name = 'data_fire_extracted_%02d'%(data_set_count)\n",
    "fire_data_loc = os.path.join(extracted_data_base_loc, fire_data_set_name)\n",
    "fire_data_file_name = '{}.pkl'.format(fire_data_set_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet and Label Specific (Train and Test Data Prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data_set_name = 'dataset_%03d_label_%03d_%s'%(data_set_count, label_count, FM_label_type)\n",
    "\n",
    "prepared_data_loc = os.path.join(prepared_data_base_loc, prepared_data_set_name)\n",
    "os.system('mkdir -p %s'%prepared_data_loc)\n",
    "\n",
    "prepared_data_file_name = '{}.pkl'.format(prepared_data_set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate seed for the random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = generate_seed()\n",
    "random_state = init_random_generator(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Pickled Extracted Data (Train, Test) from WRF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Train/Test Data Saved in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt_extracted = pd.read_pickle(os.path.join(extracted_data_loc, extracted_data_file_name))\n",
    "#df_tt_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Fire Data Saved in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fire_data_file_handle = open(os.path.join(fire_data_loc, fire_data_file_name), 'rb')\n",
    "fire_data_extracted = pickle.load(fire_data_file_handle)\n",
    "fire_data_file_handle.close()\n",
    "print('Read fire data from \"{}\" at \"{}\"'.format(fire_data_file_name, fire_data_loc))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fire_data_extracted['Woosley'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure The Train/test and Fire Data Have the Same Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_extracted.keys() == fire_data_extracted['Woosley'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Column Names in the Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_identity, keys_FM, \\\n",
    "keys_U10, keys_V10, keys_UMag10, \\\n",
    "keys_T2, keys_RH, keys_PREC, keys_SW, \\\n",
    "                            keys_HGT = get_keys_from_extracted_data (df_tt_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_FM_Binary, keys_FM_MC = define_binary_and_MC_FM_labels (keys_FM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Groups of Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (FM_label_type == 'Regression'):\n",
    "    keys_labels = keys_FM\n",
    "elif (FM_label_type == 'Binary'):\n",
    "    keys_labels = keys_FM + keys_FM_Binary\n",
    "elif (FM_label_type == 'MultiClass'):\n",
    "    keys_labels = keys_FM + keys_FM_MC\n",
    "else:\n",
    "    raise ValueError('Invalid \"label_type\": {} in \"FM_labels\". \\\n",
    "                    \\nValid types are: \"Regression\", \"MultiClass\", and \"Binary\"'.format(\\\n",
    "                                                                            FM_label_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = json_content_prep_data['features']['features_to_use']\n",
    "keys_features = []\n",
    "if 'UMag10' in features_to_use:\n",
    "    keys_features += keys_UMag10 \n",
    "if 'T2' in features_to_use:\n",
    "    keys_features += keys_T2\n",
    "if 'RH' in features_to_use:\n",
    "    keys_features += keys_RH \n",
    "if 'PREC' in features_to_use:\n",
    "    keys_features += keys_PREC\n",
    "if 'SW' in features_to_use:\n",
    "    keys_features += keys_SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Compute New Columns or Remove Some"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Wind Magnitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt_prep = compute_wind_mag (df_tt_extracted, keys_U10, keys_V10, keys_UMag10)\n",
    "\n",
    "'''\n",
    "fire_data_prep = dict()\n",
    "for fire_name in fire_data_extracted.keys():\n",
    "    fire_data_prep[fire_name] = compute_wind_mag (fire_data_extracted[fire_name], \n",
    "                                                  keys_U10, keys_V10, keys_UMag10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep[keys_U10 + keys_V10 + keys_UMag10]\n",
    "#fire_data_prep['Woosley'][keys_U10 + keys_V10 + keys_UMag10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Wind Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt_prep = drop_wind_components (df_tt_prep, keys_U10, keys_V10)\n",
    "\n",
    "'''\n",
    "for fire_name in fire_data_prep.keys():\n",
    "    fire_data_prep[fire_name] = drop_wind_components (\\\n",
    "                                        fire_data_prep[fire_name], keys_U10, keys_V10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep[keys_UMag10]\n",
    "#fire_data_prep['Woosley'][keys_UMag10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Binary FM Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FM_label_type == 'Binary':\n",
    "    df_tt_prep = compute_binary_FM_labels(df_tt_prep, \\\n",
    "                                          keys_FM, keys_FM_Binary, FM_binary_threshold)\n",
    "'''\n",
    "for fire_name in fire_data_prep.keys():\n",
    "    fire_data_prep[fire_name] = compute_binary_FM_labels (fire_data_prep[fire_name], \\\n",
    "                                      keys_FM, keys_FM_Binary, FM_binary_threshold)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_tt_prep.keys())\n",
    "#len(fire_data_prep['Woosley'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep[keys_FM + keys_FM_Binary][985:995]\n",
    "#fire_data_prep['Woosley'][keys_FM +keys_FM_Binary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute MC FM Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FM_label_type == 'MultiClass':\n",
    "    df_tt_prep = compute_MC_FM_labels(df_tt_prep, \\\n",
    "                                      keys_FM, keys_FM_MC, FM_MC_levels)\n",
    "'''\n",
    "for fire_name in fire_data_prep.keys():\n",
    "    fire_data_prep[fire_name] = compute_MC_FM_labels (fire_data_prep[fire_name], \\\n",
    "                                      keys_FM, keys_FM_MC, FM_MC_levels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tt_prep[keys_FM + keys_FM_MC]\n",
    "#fire_data_prep['Woosley'][keys_FM + keys_FM_MC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot FM Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM_hr = json_content_prep_data['qoi_to_plot']['FM_hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_FM_labels (df_tt_prep, FM_label_type, FM_hr, \\\n",
    "                prepared_data_set_name, prepared_data_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into Identity, Features, and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tt_prep = split_data_into_groups (df_tt_prep, \\\n",
    "                                       keys_identity, keys_labels, keys_features)\n",
    "'''\n",
    "data_tt_prep, data_fire_prep = split_data_into_groups (\\\n",
    "                                            df_tt_prep, fire_data_prep, \\\n",
    "                                            keys_identity, keys_labels, keys_features)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "prepared_data = {'tt': data_tt_prep,\n",
    "                 'fire': data_fire_prep}\n",
    "'''\n",
    "prepared_data = data_tt_prep\n",
    "with open(os.path.join(prepared_data_loc, prepared_data_file_name), 'wb') as file_handle:\n",
    "    pickle.dump(prepared_data, file_handle)\n",
    "print('Wrote prepared data in \"{}\" at \"{}\"'.format(prepared_data_file_name, prepared_data_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Test The Prepared Data Saved in Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(prepared_data_loc, prepared_data_file_name), 'rb') as file_handle:\n",
    "    prepared_data = pickle.load(file_handle)\n",
    "print('Read prepared data from \"{}\" at \"{}\"'.format(prepared_data_file_name, prepared_data_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_data_read['identity'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_data_read['labels'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepared_data_read['features'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global End Time and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_final_memory = process.memory_info().rss\n",
    "global_end_time = timer()\n",
    "global_memory_consumed = global_final_memory - global_initial_memory\n",
    "print('Total memory consumed: {:.3f} MB'.format(global_memory_consumed/(1024*1024)))\n",
    "print('Total computing time: {:.3f} s'.format(global_end_time - global_start_time))\n",
    "print('=========================================================================')\n",
    "print(\"SUCCESS: Done Preparation of Data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_ml_conda",
   "language": "python",
   "name": "py3_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
